# -*- coding: utf-8 -*-
"""Georges_FinalCode.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oqmbX-elI-0NgpOXjJ01nwHlx2qQDtOy
"""

import os
from google.colab import drive
drive.mount('/content/drive/', force_remount=True)
os.chdir("/content/drive/My Drive/Colab Notebooks")

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Load dataset
df = pd.read_csv("mentalhealth_global.csv", low_memory = False)
display(df)

df.info()

# Remove missing values
df.dropna(axis=0, inplace = True)

# Replace 'code' column
df.drop(['Code'], axis=1)

# Assign numeric values to categories(countries)
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['Code'] = le.fit_transform(df['Entity'])
display(df)

# Rename columns and removing percentages
df.columns = ['country', 'code', 'year', 'schizophrenia', 'bipolar_disorder', 'eating_disorders', 'anxiety_disorders', 'drug_use_disorders', 'depression', 'alcohol_use_disorders']

display(df)

print(df.describe())

# Create a linear regression based on the mean of each mental health disorder from each year
df1 = df.groupby("year")[('schizophrenia', 'bipolar_disorder', 'eating_disorders', 'anxiety_disorders', 'drug_use_disorders', 'depression', 'alcohol_use_disorders')].mean()
print(df1)

# Use for-loop to apply code to each column in a single block
for c in df1.columns:

    # Select features and labels
    X = df1.index.values.reshape(-1, 1)
    y = df1[c].values.reshape(-1, 1)

    # Split the data into train and test sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    # Scale the data
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Create linear regression model
    model = LinearRegression()

    # Train the model on the training data
    model.fit(X_train_scaled, y_train)

    # Make predictions on the test data
    y_pred = model.predict(X_test)

    # Calculate the R^2 score for the model
    r2 = model.score(y_test, y_pred)
    print(f"R2 score for {c}: {r2}")

    # Cross-validation
    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)
    print(f"Cross-validation scores: {cv_scores}")

    # Make scatterplots
    plt.scatter(X_test, y_test, color='black')
    plt.plot(X_test, model.predict(X_test_scaled), color='blue')
    plt.title(c)
    plt.xlabel('Year')
    plt.ylabel('Rate')
    plt.show()

"""Time-series (with and without ARIMA)"""

pip install tslearn

pip install --upgrade statsmodels

# A few additonal imports for time-series clustering
from tslearn.clustering import TimeSeriesKMeans
from tslearn.preprocessing import TimeSeriesScalerMeanVariance
from statsmodels.tsa.arima.model import ARIMA
from sklearn.metrics import mean_squared_error

time_series_data = []

# Extract time series data
for c in df1.columns:
    time_series = df1[c].values
    time_series_data.append(time_series)

# Compile time series data into a  numpy array
X1 = np.vstack(time_series_data)

# Scale the data
X_scaled = TimeSeriesScalerMeanVariance().fit_transform(X1)

# Apply K-Means clustering
n_clusters = 7
model = TimeSeriesKMeans(n_clusters=n_clusters, random_state=42)
y_pred1 = model.fit_predict(X_scaled)

# Visualize the clusters
for cluster_id in range(n_clusters):
    cluster_indices = np.where(y_pred1 == cluster_id)[0]
    plt.figure(figsize=(12, 6))
    for idx in cluster_indices:
        plt.plot(df1.index, X1[idx], label=f'{df1.columns[idx]}')
    plt.title(f'Cluster {cluster_id + 1}')
    plt.xlabel('Year')
    plt.ylabel('Rate')
    plt.legend()
    plt.show()

# Number of years to forecast
n_years_forecast = 10

# Create a list to store time series data and forecasts
time_series_data = []
forecast_data = []

for c in df1.columns:
    # Fit an ARIMA model
    arimamodel = ARIMA(time_series, order=(5,1,0))
    arimamodel_fit = model.fit()

    # Make predictions for the next n_years_forecast years
    forecast = model_fit.forecast(steps=n_years_forecast)

    # Append the time series and forecasts to the lists
    time_series_data.append(time_series)
    forecast_data.append(forecast)

# Visualize the forecasts
years = df1.index.tolist()[-1] + np.arange(1, n_years_forecast + 1)
for i in range(len(df1.columns)):
    plt.figure(figsize=(12, 6))
    plt.plot(df1.index, time_series_data[i], label=f'Actual {df1.columns[i]}', color='blue')
    plt.plot(years, forecast_data[i], label=f'Forecast {df1.columns[i]}', color='red')
    plt.title(f'{df1.columns[i]} Forecast for the Next {n_years_forecast} Years')
    plt.xlabel('Year')
    plt.ylabel('Rate')
    plt.legend()
    plt.show()

# Calculate Mean Squared Error for each forecast
mse_scores = []
for i in range(len(df1.columns)):
    mse = mean_squared_error(time_series_data[i][-n_years_forecast:], forecast_data[i])
    mse_scores.append(mse)
    print(f"Mean Squared Error for {df1.columns[i]}: {mse}")